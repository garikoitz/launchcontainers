# Input guide:
# replace the part of this template config.yaml with your own options
# comments for each option are above it
# Input value type:
#       str: string, python will read if as string, type a space after : and input the string directly
#       bool: boolean value, True of False, needs to be capitalize first letter
#       int: integer, similar to string, type a space after :
#       None: python None type, Usually used for optional arguement, don't put anything after column, not even ""
general:
  # Base directory of project
  basedir: /scratch/tlei/paper_dv
  # Name of bids directory, 1 level under basedir, must contain dataset_description
  bidsdir_name: BIDS
  # Directory contains singularity images
  containerdir: /scratch/tlei/containers
  # Name of the container
  # VALID OPTIONS: 
  # Convert dcm to nifti: heudiconv
  # preprocessing: presurfer and nordic
  # fMRIprep
  # DWI pipelines:
  ## freesurferator, rtp2-preproc, rtp2-pipeline (RTP2)
  ## anatrois, rtppreproc, rtp-pipeline (RTP_old)
  # prf pipelines:
  ## prfprepare, prfanalyze-vista, prfresult
  # glm :
  ## l1_glm
  container: rtppreproc
  # Name of analysis folder; if input 01, need to add quote ""
  analysis_name: paper_dv-main
  # Place the computing will be held. 
  # VALID OPTIONS: local, BCBL, DIPC.
  host: DIPC
  # Whether force to overwrite
  force: True
  # Verbosity of command-line console. If true, only print information at level: CRITICAL (based on python logging package)
  print_command_only: False
  # Log directory to store launchcontainers logging 
  # VALID OPTIONS: analysis_dir or full path you want
  # This log dir will be used for dask_log and launchcontainer log
  log_dir: /scratch/tlei/paper_dv/lc_launch_log
  # Name of launchcontainers log file
  log_filename: lc_log

container_specific:
  anatrois:
    # Version identifier for container 
    version: 4.5.3-7.3.2
    # Pre-run freesurfer or not?
    pre_fs: False
    # Directory name of your pre-run freesurfer, this directory should be under /basedir/bidsdir/derivatives
    prefs_dir_name: anatrois_4.6.1-7.3.2
    # Analysis name of pre-run freesurfer
    prefs_analysis_name: "6prefs_from_fmriprep"
    # A super identifier to find the pattern no need to change
    prefs_zipname: '^anatrois_S.*\.zip$'
    # optional
    # Freesurfer annotefiles
    annotfile: 
    # MNI roi zip file
    mniroizip: 
    # for multiple session assign to single T1
    # input a src session id
    # the program will loop for the subeselist, if it detect src_session_id, it will do nothing
    # if it detects other session id, it will create a symlink ot the src_session folder in the anatrois or freesurferator folder
    use_src_session: T01    
  rtppreproc:
    # Version identifier for container
    version: 1.2.0-3.0.3   
    # anatrois or freesurferator dir, used to find the brainmask
    precontainer_anat: freesurferator_0.2.1_7.4.1
    # Analysis name 
    anat_analysis_name: paper_dv-main
    # optional
    # if your encoding direction DWI is multishell sequence and they are in seperate files
    separated_shell_files: True
    # If reverse phase encoding is applied in the sequence
    # It checks if there is a reverse phase encoding acquisition
    # Old dcm2nixx will not create empty bvec and bval files if there was an acquisition with just b0-s
    rpe: True  

  freesurferator:
    # Version identifier for container 
    version: 0.2.1_7.4.1
    # Pre-run freesurfer or not?
    pre_fs: True
    # Directory name of your pre-run freesurfer, this directory should be under /basedir/bidsdir/derivatives
    prefs_dir_name: anatrois_4.5.3-7.3.2
    # Analysis name of pre-run freesurfer
    prefs_analysis_name: "01"
    # A super identifier to find the pattern 
    # The pattern is using python package re, useually you don't need to change this if you are using simply the 
    # RTP2-pipeline
    prefs_zipname: '^freesurferator.*.zip$|^anatrois.*\.zip$'
    # If you want to use the control points created in the previous analysis (control.dat), set this True:
    control_points: False
    # If you created control points, you'll have an unzipped folder in the output analysis. Fill prefs_unzipname
    # with the name of the unzipped folder to let launchcontainers create a symbolic link to the control.dat  
    prefs_unzipname: 'S.*$'
    # optional 
    # Freesurfer annotefiles
    annotfile:  /scratch/tlei/paper_dv/code/script_paper-dorsalventral/DV_annots.zip
    # MNI roi zip file
    mniroizip: 
    # for multiple session assign to single T1
    # input a src session id
    # the program will loop for the subeselist, if it detect src_session_id, it will do nothing
    # if it detects other session id, it will create a symlink ot the src_session folder in the anatrois or freesurferator folder
    use_src_session: T01    

  rtp2-preproc:
    # Version identifier for container      
    version: 0.2.2_3.0.4  
    # anatrois or freesurferator dir, used to find the brainmask
    precontainer_anat: freesurferator_0.2.1_7.4.1
    # Analysis name 
    anat_analysis_name: week1
    # optional
    # if your encoding direction DWI is multishell sequence and they are in seperate files
    separated_shell_files: False
    # If reverse phase encoding is applied in the sequence
    # It checks if there is a reverse phase encoding acquisition
    # if not, launchcontainers will create mock files
    rpe: True
    # Use qmap file or not?
    use_qmap: False
    # Directory name of your pre-run freesurfer, this directory should be under /basedir/bidsdir/derivatives
    qmap_dir_name: mrVista_0.1.0
    # Analysis name of pre-run freesurfer
    qmap_analysis_name: test_qmap
    # qunatitative MRI maps, must be nifti format
    # A super identifier to find the pattern 
    qmap_fname: '^qmap.*\.zip$'

  rtp2-pipeline:
    # Version identifier for container 
    version: 0.1.0_3.0.4rc20
    # anatrois or freesurferator dir, used to find the brainmask and fs/ROIs
    precontainer_anat: freesurferator_0.2.0-7.4.1rc19
    # Analysis name 
    anat_analysis_name: control_points_02
    # rtppreproc or rtp2-preproc dir, used to find the dwi.nii.gz, bvec and bval
    precontainer_preproc: rtp2-preproc_0.1.0_3.0.4rc31
    # Analysis name 
    preproc_analysis_name: control_points_02
    # optional
    # Path to tractparams files, needs to be a .csv
    tractparams: /home/tlei/tlei/LMC_DWI_course/scripts/tractparams_short_course.csv
    # Path to brain.nii.gz of freesurfer If use fsmask or define manually, this option is set in case you need 
    fsmask: /home/tlei/Desktop/FG.nii.gz
    # zip file for rtp2-pipeline
    qmap_zip: /home/tlei/Desktop/annnnooott.zip

host_options:
    BCBL:
      # SGE manager
      use_module: False 
      apptainer: apptainer/latest
      maxwall: 10
      manager: sge
      name: "anatrois"
      # Dask worker options
      # Total number of cores per job (it was core for BCBL)
      cores: 6
      # Total amount of memory per job (it was mem for BCBL)
      memory: 32G
      # Number of Python processes per job
      processes: 1
      # Network interface to use like eth0 or ib0
      interface: lo
      # Number of seconds to wait if a worker can not find a scheduler
      death-timeout: 100
      # Location of fast local storage like /scratch or $TMPDIR
      local-directory: null
      # It was que in BCBL
      queue: long.q
      project: null
      walltime: 25:30:00'
      extra: []
      env-extra: []
      job-extra: []
      resource-spec: null
      bind_options: ['/bcbl', '/tmp','/scratch']

    DIPC:
      # SLURM manager
      memory: 32G
      # to mimic this: 
      #--partition=general \
      #--qos=${qos} \ # qos can be : regular test long xlong serial
      queue: general
      job_extra_directives: [--qos=regular] 
      cores: 20
      walltime: '10:00:00'
      # for SLURM, it is always False
      use_module: False
      apptainer: Apptainer
      manager: slurm
      system: scratch
      name: "rtppreproc"
      tmpdir: /scratch/tlei/tmp
      bind_options: ['/scratch']

    local:
      # Local machine, ubuntu, MacOS
      # if the local machine use module load this option will give you different version of job-queue cmd
      use_module: False
      apptainer: apptainer/latest
      # Copy the example list: for BCBL we need ['/bcbl', '/tmp', '/export']; for okazaki we need ['/fileserver', '/tmp']
      bind_options: ['/bcbl', '/tmp', '/scratch', '/export']
      manager: 'local'
      # This can only be serial, parallel, or dask_worker any other options will make it fail.
      launch_mode: 'parallel'
      # Arguments below only affect to parallel launch mode
      njobs: 5
      memory_limit: '32GiB'
      threads_per_worker: 6